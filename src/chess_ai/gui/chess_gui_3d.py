"""
Interface 3D Simple pour Chess AI
=================================

Affichage pseudo-3D simple avec Pygame.
Interaction directe et visuelle.
"""

import pygame
import chess
import math
import sys
from typing import Tuple, List, Optional
from dataclasses import dataclass

# Import des modules internes
from ..core.environment import ChessEnvironment

# Import de l'√©valuateur de r√©f√©rence
try:
    from ..ai.reference_evaluator import get_reference_evaluator

    REFERENCE_AVAILABLE = True
except ImportError:
    REFERENCE_AVAILABLE = False
    print("‚ö†Ô∏è  √âvaluateur de r√©f√©rence non disponible")

# Import de l'entra√Ænement hybride
try:
    from ..ai.hybrid_training import HybridSelfPlayTrainer, HybridTrainingConfig

    HYBRID_TRAINING_AVAILABLE = True
except ImportError:
    HYBRID_TRAINING_AVAILABLE = False
    print("‚ö†Ô∏è  Entra√Ænement hybride non disponible")

# Import de l'IA (optionnel)
try:
    from .ai_integration import AlphaZeroPlayer

    AI_AVAILABLE = True
except ImportError:
    AI_AVAILABLE = False
    print("‚ö†Ô∏è  Module IA non disponible (PyTorch requis)")

# Import du module d'entra√Ænement (optionnel)
try:
    from ..ai.training import SelfPlayTrainer, TrainingConfig
    import torch

    TRAINING_AVAILABLE = True
except ImportError:
    TRAINING_AVAILABLE = False
    print("‚ö†Ô∏è  Module d'entra√Ænement non disponible")

# Import de l'IA hybride (nouvelle)
try:
    from ..ai.hybrid_engine import HybridAI, AIMode, GameContext, create_hybrid_ai

    HYBRID_AI_AVAILABLE = True
except ImportError:
    HYBRID_AI_AVAILABLE = False
    print("‚ö†Ô∏è  IA hybride non disponible")


@dataclass
class Camera3D:
    """Configuration simple de la cam√©ra 3D."""

    rotation_x: float = -30.0  # Vue l√©g√®rement inclin√©e vers le bas
    rotation_y: float = 0.0  # Rotation horizontale
    zoom: float = 1.0  # Facteur de zoom


class SimpleChessGUI3D:
    """Interface 3D simple pour jouer aux √©checs avec mode d'entra√Ænement."""

    def __init__(self):
        # Configuration de base
        self.WINDOW_WIDTH = 1200
        self.WINDOW_HEIGHT = 900
        self.BOARD_SIZE = 600
        self.CELL_SIZE = self.BOARD_SIZE // 8

        # Couleurs
        self.COLORS = {
            "light_square": (240, 217, 181),
            "dark_square": (181, 136, 99),
            "white_piece": (255, 255, 255),
            "black_piece": (50, 50, 50),
            "selected": (255, 255, 0, 128),
            "possible_move": (0, 255, 0, 128),
            "ai_suggestion": (0, 150, 255, 100),  # Bleu pour suggestions IA
            "background": (100, 100, 100),
            # Couleurs pour la barre d'√©valuation
            "eval_white": (240, 240, 240),
            "eval_black": (60, 60, 60),
            "eval_border": (0, 0, 0),
            "eval_text": (255, 255, 255),
            # Couleurs pour la barre de r√©f√©rence (Stockfish)
            "ref_border": (0, 150, 255),
            "ref_black": (30, 30, 80),
            "ref_white": (200, 220, 255),
            # Couleurs pour la barre IA
            "ai_border": (255, 150, 0),
            "ai_black": (80, 40, 0),
            "ai_white": (255, 220, 180),
        }

        # √âtat du jeu
        self.environment = ChessEnvironment()
        self.camera = Camera3D()

        # IA (optionnel)
        self.ai_player = None
        self.ai_enabled = False
        self.show_ai_hints = False
        self.ai_analysis = None

        # Barres d'√©valuation
        self.current_evaluation = 0.0  # -1.0 (noir) √† +1.0 (blanc) - IA
        self.evaluation_history = []  # Historique des √©valuations IA
        self.reference_evaluation = 0.0  # √âvaluation de r√©f√©rence (Stockfish)
        self.reference_history = []  # Historique r√©f√©rence
        self.show_evaluation_bar = True
        self.eval_bar_width = 40
        self.eval_bar_height = 400

        # √âvaluateur de r√©f√©rence
        self.reference_evaluator = None
        if REFERENCE_AVAILABLE:
            try:
                self.reference_evaluator = get_reference_evaluator()
            except Exception as e:
                print(f"‚ö†Ô∏è  Impossible d'initialiser l'√©valuateur de r√©f√©rence : {e}")

        # Mode IA vs IA
        self.ai_vs_ai_mode = False
        self.ai_player_white = None
        self.ai_player_black = None
        self.auto_play_delay = 2000  # 2 secondes entre les coups
        self.last_move_time = 0
        self.game_paused = False

        # Mode IA continue contre joueur
        self.ai_auto_play = False  # IA joue automatiquement ses coups
        self.ai_delay = 1500  # D√©lai avant que l'IA joue (ms)
        self.waiting_for_ai = False  # En attente du coup IA
        self.ai_move_time = 0  # Temps du dernier coup pour l'IA
        self.ai_color = None  # Couleur de l'IA (None = auto-d√©tection)
        self.player_color = None  # Couleur du joueur (None = auto-d√©tection)

        # Entra√Ænement pendant le jeu
        self.learning_from_games = (
            True  # üöÄ ACTIV√â PAR D√âFAUT ! Apprendre des parties contre le joueur
        )
        self.current_game_moves = []  # Mouvements de la partie actuelle
        self.game_start_time = None  # Temps de d√©but de partie
        self.collected_games = []  # Parties collect√©es pour l'entra√Ænement

        # Mode d'entra√Ænement
        self.training_mode = False
        self.trainer = None
        self.hybrid_trainer = None  # Nouveau : trainer hybride
        self.use_hybrid_training = True  # Par d√©faut, utiliser l'hybride
        self.use_hybrid_trainer = True  # Alias pour compatibilit√©
        self.training_iteration = 0
        self.training_games_played = 0
        self.current_training_game = None
        self.training_auto_play = False
        self.training_speed = 1000  # ms entre les coups en mode entra√Ænement

        # Entra√Ænement automatique jusqu'√† convergence
        self.auto_training_active = False
        self.auto_training_iteration = 0
        self.auto_training_max_iterations = 100  # Augment√© de 20 √† 100
        self.auto_training_target_diff = 0.25
        self.auto_training_target_corr = 0.7
        self.auto_training_paused = False
        self.auto_training_speed = 100  # Acc√©l√©r√© de 500 √† 100ms
        self.auto_training_game_count = 0

        if AI_AVAILABLE:
            try:
                self.ai_player = AlphaZeroPlayer()
                self.ai_enabled = True
                print("ü§ñ IA AlphaZero activ√©e")

                # Cr√©er deux IA diff√©rentes pour le mode vs IA
                self.ai_player_white = AlphaZeroPlayer(
                    use_mcts=True, mcts_simulations=200, c_puct=1.4
                )
                self.ai_player_black = AlphaZeroPlayer(
                    use_mcts=True, mcts_simulations=300, c_puct=1.6
                )
                print("ü§ñ Mode IA vs IA disponible (touche A)")

                # Initialiser l'entra√Æneur si disponible
                if TRAINING_AVAILABLE:
                    self.setup_trainer()

            except Exception as e:
                print(f"‚ö†Ô∏è  IA non disponible : {e}")

        # Initialiser l'IA hybride (nouvelle)
        self.hybrid_ai = None
        self.hybrid_ai_enabled = False
        if HYBRID_AI_AVAILABLE:
            try:
                self.hybrid_ai = create_hybrid_ai()
                self.hybrid_ai_enabled = True
                self.current_ai_mode = AIMode.ADAPTIVE
                print("üöÄ IA Hybride activ√©e (Stockfish + Neural + MCTS)")
                print("   ‚Ä¢ Mode adaptatif intelligent")
                print("   ‚Ä¢ Force imm√©diate de niveau ma√Ætre")
            except Exception as e:
                print(f"‚ö†Ô∏è  IA Hybride non disponible : {e}")

        # Pr√©f√©rence IA : utiliser hybride si disponible, sinon standard
        self.use_hybrid_ai = self.hybrid_ai_enabled

        # √âtat de l'interface
        self.selected_square = None
        self.possible_moves = []
        self.legal_moves_from_selected = []
        self.dragging_camera = False
        self.last_mouse_pos = (0, 0)

        # Initialisation Pygame
        pygame.init()
        self.screen = pygame.display.set_mode((self.WINDOW_WIDTH, self.WINDOW_HEIGHT))
        pygame.display.set_caption("Chess AI - Vue 3D Simple")
        self.clock = pygame.time.Clock()
        self.font = pygame.font.Font(None, 36)

        print("üéÆ Interface 3D Simple initialis√©e !")
        print("üñ±Ô∏è  Contr√¥les :")
        print("   ‚Ä¢ Clic gauche : S√©lectionner/D√©placer pi√®ces")
        print("   ‚Ä¢ Clic droit + glisser : Rotation de la cam√©ra")
        print("   ‚Ä¢ Molette : Zoom")
        print("   ‚Ä¢ R : R√©initialiser cam√©ra")
        if self.ai_enabled:
            print("   ‚Ä¢ H : Suggestions IA")
            print("   ‚Ä¢ A : Analyse position")
            print("   ‚Ä¢ I : Coup IA")
            if TRAINING_AVAILABLE:
                print("   ‚Ä¢ T : Mode entra√Ænement")
                print("   ‚Ä¢ S : D√©marrer/Arr√™ter auto-jeu")

    def setup_trainer(self):
        """Initialise l'entra√Æneur pour le mode d'entra√Ænement."""
        try:
            # Configuration d'entra√Ænement adapt√©e √† l'interface
            config = TrainingConfig(
                games_per_iteration=5,  # R√©duit pour tests plus rapides
                mcts_simulations=100,  # Simulations r√©duites pour la vitesse
                epochs_per_iteration=3,  # Moins d'√©poques
                batch_size=8,  # Batch plus petit
                save_interval=1,  # üöÄ SAUVEGARDER APR√àS CHAQUE IT√âRATION !
            )

            device = "cuda" if torch.cuda.is_available() else "cpu"

            # Entra√Æneur classique (AlphaZero)
            self.trainer = SelfPlayTrainer(config, device=device)

            # Entra√Æneur hybride (Stockfish + AlphaZero) avec ADAPTATION AUTOMATIQUE
            if HYBRID_TRAINING_AVAILABLE:
                hybrid_config = HybridTrainingConfig(
                    games_per_iteration=5,  # R√©duit pour tests plus rapides
                    mcts_simulations=50,  # Moins car Stockfish compense
                    epochs_per_iteration=3,
                    batch_size=8,
                    save_interval=1,  # üöÄ SAUVEGARDER APR√àS CHAQUE IT√âRATION !
                    use_stockfish_guidance=True,
                    stockfish_depth=15,  # üöÄ Niveau club fort (~1800-2000 ELO)
                    # üé≤ VARIATION DE PROFONDEUR pour √©viter la r√©p√©titivit√©
                    vary_stockfish_depth=True,  # Activer variation
                    depth_range=(10, 20),  # Facile √† difficile
                    depth_variation_mode="adaptive",  # Mode intelligent
                    # üöÄ ADAPTATION AUTOMATIQUE PAR D√âFAUT !
                    adaptive_training=True,  # Adaptation activ√©e
                    neural_confidence_threshold=0.8,  # Seuil de confiance initial
                    # üéØ √âVALUATIONS STOCKFISH PAR D√âFAUT !
                    use_stockfish_values=True,  # Toujours utiliser Stockfish pour les valeurs
                    stockfish_eval_depth=15,  # üöÄ M√™me force pour √©valuations
                )
                self.hybrid_trainer = HybridSelfPlayTrainer(
                    hybrid_config, device=device
                )
                print(f"üèãÔ∏è  Entra√Æneur HYBRIDE initialis√© sur {device}")
                print(f"   ‚ö° Force imm√©diate gr√¢ce √† Stockfish")
                print(f"   üéØ √âvaluation pr√©cise des positions par Stockfish")
                print(f"   üìà Neural Network apprend les VRAIES valeurs !")
                print(f"   üé≤ Variation automatique de profondeur Stockfish (10-20)")
                print(f"   üîÑ ADAPTATION AUTOMATIQUE activ√©e par d√©faut")
                print(f"   üéì ENTRA√éNEMENT APR√àS CHAQUE PARTIE activ√©")
            else:
                self.hybrid_trainer = None
                print(f"‚ö†Ô∏è  Entra√Æneur hybride non disponible")

            print(f"üèãÔ∏è  Entra√Æneur classique initialis√© sur {device}")
            print("   ‚Ä¢ Mode entra√Ænement disponible")
            print(f"   ‚Ä¢ Hybride: {'‚úÖ' if self.hybrid_trainer else '‚ùå'}")

            # üöÄ INFORMATION UTILISATEUR SUR LES FONCTIONNALIT√âS AUTOMATIQUES
            if self.hybrid_trainer:
                print()
                print("üéì APPRENTISSAGE CONTINU ACTIV√â PAR D√âFAUT !")
                print("=" * 50)
                print("‚úÖ L'IA apprendra automatiquement de toutes vos parties")
                print("‚úÖ Adaptation automatique du ratio Stockfish/Neural Network")
                print("‚úÖ Entra√Ænement imm√©diat apr√®s chaque partie")
                print("‚úÖ √âvaluations pr√©cises avec Stockfish")
                print()
                print("üìà Plus vous jouez, plus l'IA s'am√©liore !")
                print("üîÑ Le syst√®me s'adapte selon les performances de l'IA")
                print()

            # üöÄ IMPORTANT : D√©finir le trainer principal pour l'interface
            # Utiliser l'hybride si disponible, sinon le classique
            if self.hybrid_trainer:
                self.trainer = self.hybrid_trainer  # Le trainer principal = hybride
                print("üéØ Trainer principal: HYBRIDE (Stockfish + Neural Network)")
            else:
                print("üéØ Trainer principal: CLASSIQUE (Neural Network seul)")

        except Exception as e:
            print(f"‚ö†Ô∏è  Entra√Æneur non disponible : {e}")
            self.trainer = None
            self.hybrid_trainer = None

    def toggle_training_mode(self):
        """Active/d√©sactive le mode d'entra√Ænement."""
        # Utiliser le trainer hybride si disponible, sinon le classique
        current_trainer = self.hybrid_trainer if self.hybrid_trainer else self.trainer

        if not current_trainer:
            print("‚ùå Mode entra√Ænement non disponible")
            return

        self.training_mode = not self.training_mode

        if self.training_mode:
            trainer_type = (
                "HYBRIDE (Stockfish+NN)" if self.hybrid_trainer else "CLASSIQUE"
            )
            print(f"üèãÔ∏è  MODE ENTRA√éNEMENT {trainer_type} ACTIV√â")
            print("üöÄ D√©marrage automatique de l'entra√Ænement...")
            # D√©marrer automatiquement l'entra√Ænement
            self.start_training_iteration()
        else:
            print("üéÆ Mode normal activ√©")
            self.training_auto_play = False

    def start_training_iteration(self):
        """D√©marre une it√©ration d'entra√Ænement avec visualisation."""
        # Utiliser le trainer hybride si disponible, sinon le classique
        current_trainer = self.hybrid_trainer if self.hybrid_trainer else self.trainer

        if not current_trainer or not self.training_mode:
            return

        trainer_type = "hybride" if self.hybrid_trainer else "classique"
        print(
            f"\nüöÄ D√©marrage it√©ration d'entra√Ænement {trainer_type} #{self.training_iteration + 1}"
        )

        # R√©initialiser pour une nouvelle partie d'entra√Ænement
        self.environment.board = chess.Board()
        self.training_auto_play = True
        self.training_games_played = 0
        self.last_move_time = pygame.time.get_ticks()

        # Utiliser les IA du trainer pour l'auto-jeu
        self.ai_player_white = AlphaZeroPlayer(
            use_mcts=True,
            mcts_simulations=current_trainer.config.mcts_simulations,
            c_puct=current_trainer.config.c_puct,
        )
        self.ai_player_black = AlphaZeroPlayer(
            use_mcts=True,
            mcts_simulations=current_trainer.config.mcts_simulations,
            c_puct=current_trainer.config.c_puct,
        )

        print(f"üéØ Objectif: {self.trainer.config.games_per_iteration} parties")

    def start_automatic_training(self):
        """Lance l'entra√Ænement automatique jusqu'√† convergence avec visualisation."""
        # üöÄ UTILISER L'ENTRA√éNEUR HYBRIDE PAR D√âFAUT si disponible
        current_trainer = self.hybrid_trainer if self.hybrid_trainer else self.trainer

        if not current_trainer:
            print("‚ùå Entra√Æneur non disponible")
            return

        trainer_type = (
            "HYBRIDE avec adaptation automatique"
            if self.hybrid_trainer
            else "CLASSIQUE"
        )

        print(f"\nüéØ ENTRA√éNEMENT AUTOMATIQUE {trainer_type}")
        print("=" * 60)
        print("L'IA va s'entra√Æner automatiquement jusqu'√† atteindre")
        print("des performances satisfaisantes par rapport √† Stockfish!")

        if self.hybrid_trainer:
            print()
            print("üîÑ FONCTIONNALIT√âS ACTIV√âES PAR D√âFAUT:")
            print("  ‚Ä¢ Adaptation automatique du ratio Stockfish/NN")
            print("  ‚Ä¢ Entra√Ænement imm√©diat apr√®s chaque partie")
            print("  ‚Ä¢ √âvaluations Stockfish pr√©cises")
            print("  ‚Ä¢ Apprentissage des meilleures politiques Stockfish")

        print()
        print("üéÆ CONTR√îLES PENDANT L'ENTRA√éNEMENT:")
        print("  ‚Ä¢ √âCHAP : Arr√™ter l'entra√Ænement")
        print("  ‚Ä¢ ESPACE : Pause/Reprendre")
        print("  ‚Ä¢ + : Acc√©l√©rer (moins d'attente)")
        print("  ‚Ä¢ - : Ralentir (plus d'attente)")
        print()

        # Configuration pour l'entra√Ænement automatique
        self.auto_training_active = True
        self.auto_training_iteration = 0
        self.auto_training_max_iterations = 30
        self.auto_training_target_diff = 0.25
        self.auto_training_target_corr = 0.7
        self.auto_training_paused = False
        self.auto_training_speed = 500  # ms entre les coups
        self.auto_training_game_count = 0

        # Utiliser le bon trainer
        self.trainer = current_trainer

        # D√©marrer le mode d'entra√Ænement
        self.training_mode = True

        print(f"üéØ Objectifs:")
        print(f"  ‚Ä¢ √âcart moyen < {self.auto_training_target_diff}")
        print(f"  ‚Ä¢ Corr√©lation > {self.auto_training_target_corr}")
        print(f"  ‚Ä¢ Maximum {self.auto_training_max_iterations} it√©rations")

        if self.hybrid_trainer:
            config = self.hybrid_trainer.hybrid_config
            print(f"  ‚Ä¢ Profondeur Stockfish: {config.stockfish_depth}")
            print(f"  ‚Ä¢ Seuil confiance NN: {config.neural_confidence_threshold:.2f}")

        print()
        print("üöÄ D√©marrage de l'entra√Ænement automatique...")

    def handle_training_auto_play(self):
        """G√®re l'auto-jeu en mode entra√Ænement."""
        current_time = pygame.time.get_ticks()

        # V√©rifier si on doit red√©marrer automatiquement apr√®s une it√©ration
        if (
            self.training_mode
            and not self.training_auto_play
            and hasattr(self, "last_move_time")
            and current_time > self.last_move_time
        ):
            print(
                f"üöÄ Red√©marrage automatique de l'it√©ration {self.training_iteration + 1}"
            )
            self.start_training_iteration()
            return

        if not self.training_auto_play or not self.trainer:
            return

        # V√©rifier si il est temps pour le prochain coup
        if current_time - self.last_move_time < self.training_speed:
            return

        board = self.environment.board

        # V√©rifier si la partie est termin√©e
        if board.is_game_over():
            self.finish_training_game()
            return

        # Obtenir le joueur courant
        if board.turn == chess.WHITE:
            current_ai = self.ai_player_white
            player_name = "Blanc"
        else:
            current_ai = self.ai_player_black
            player_name = "Noir"

        try:
            # Obtenir le coup de l'IA
            move = current_ai.select_move(board, temperature=0.3)

            if move and move in board.legal_moves:
                board.push(move)
                self.last_move_time = current_time
                print(f"ü§ñ {player_name}: {move}")

                # Reset des s√©lections
                self.selected_square = None
                self.possible_moves = []

                # Mettre √† jour l'√©valuation apr√®s le coup
                self.update_evaluation()

        except Exception as e:
            print(f"‚ùå Erreur IA {player_name}: {e}")
            self.training_auto_play = False

    def finish_training_game(self):
        """Termine une partie d'entra√Ænement et commence la suivante."""
        result = self.environment.board.result()
        self.training_games_played += 1

        print(f"üèÅ Partie {self.training_games_played}: {result}")

        # üöÄ ENTRA√éNEMENT IMM√âDIAT APR√àS CHAQUE PARTIE (PAR D√âFAUT) !
        current_trainer = self.hybrid_trainer if self.hybrid_trainer else self.trainer

        if current_trainer:
            try:
                # Cr√©er les donn√©es de la partie qui vient de se terminer
                from ..ai.training import GameData
                from ..ai.hybrid_training import HybridGameData
                from ..ai.network import encode_board

                # Reconstruire les donn√©es de la partie
                board = chess.Board()
                positions = []
                board_positions = []
                moves = []

                # Rejouer la partie pour extraire les positions
                for move_san in self.environment.board.move_stack:
                    positions.append(encode_board(board))
                    board_positions.append(board.copy())
                    moves.append(move_san.uci())
                    board.push(move_san)

                if positions:  # Seulement si on a des positions
                    print(f"üß† Entra√Ænement imm√©diat sur la partie termin√©e...")

                    # üöÄ UTILISER L'ENTRA√éNEMENT HYBRIDE PAR D√âFAUT si disponible
                    if self.hybrid_trainer and hasattr(
                        self.hybrid_trainer, "train_single_game_hybrid"
                    ):
                        print(f"   üìä Mode HYBRIDE avec adaptation automatique...")

                        # Calculer les valeurs et politiques Stockfish
                        values = self.hybrid_trainer._calculate_stockfish_values(
                            board_positions, result
                        )

                        # Cr√©er des politiques dummy (seront recalcul√©es par Stockfish)
                        policies = []
                        stockfish_policies = []

                        for board_pos in board_positions:
                            # Politique uniforme dummy pour MCTS
                            legal_moves = list(board_pos.legal_moves)
                            if legal_moves:
                                uniform_prob = 1.0 / len(legal_moves)
                                dummy_policy = {
                                    move: uniform_prob for move in legal_moves
                                }
                                policies.append(dummy_policy)

                                # Politique Stockfish concentr√©e sur le meilleur coup
                                try:
                                    best_move = self.hybrid_trainer.reference_evaluator.get_best_move(
                                        board_pos
                                    )
                                    if best_move and best_move in legal_moves:
                                        stockfish_policy = {}
                                        for move in legal_moves:
                                            if move == best_move:
                                                stockfish_policy[move] = 0.8
                                            else:
                                                stockfish_policy[move] = 0.2 / (
                                                    len(legal_moves) - 1
                                                )
                                        stockfish_policies.append(stockfish_policy)
                                    else:
                                        stockfish_policies.append(dummy_policy)
                                except:
                                    stockfish_policies.append(dummy_policy)
                            else:
                                policies.append({})
                                stockfish_policies.append({})

                        # Cr√©er les donn√©es de partie hybride
                        game_data = HybridGameData(
                            positions=positions,
                            policies=policies,
                            values=values,
                            result=result,
                            moves=moves,
                            game_length=len(moves),
                            stockfish_policies=stockfish_policies,
                        )

                        # Entra√Æner le r√©seau avec adaptation automatique
                        training_metrics = self.hybrid_trainer.train_single_game_hybrid(
                            game_data, verbose=True
                        )
                        print(f"   üîÑ Adaptation automatique appliqu√©e")

                    elif self.trainer and hasattr(self.trainer, "train_single_game"):
                        print(f"   üìä Mode CLASSIQUE...")

                        # Entra√Ænement classique avec √©valuations Stockfish
                        values = self.trainer._calculate_stockfish_values(
                            board_positions, result
                        )

                        # Politiques dummy
                        policies = []
                        for board_pos in board_positions:
                            legal_moves = list(board_pos.legal_moves)
                            if legal_moves:
                                uniform_prob = 1.0 / len(legal_moves)
                                dummy_policy = {
                                    move: uniform_prob for move in legal_moves
                                }
                                policies.append(dummy_policy)
                            else:
                                policies.append({})

                        game_data = GameData(
                            positions=positions,
                            policies=policies,
                            values=values,
                            result=result,
                            moves=moves,
                            game_length=len(moves),
                        )

                        training_metrics = self.trainer.train_single_game(
                            game_data, verbose=True
                        )

                    print(
                        f"‚úÖ Entra√Ænement termin√© ! Loss: {training_metrics.get('total_loss', 0):.4f}"
                    )

            except Exception as e:
                print(f"‚ö†Ô∏è Erreur lors de l'entra√Ænement automatique: {e}")
                import traceback

                traceback.print_exc()

        # V√©rifier si on a termin√© toutes les parties pour cette it√©ration
        if self.training_games_played >= current_trainer.config.games_per_iteration:
            self.complete_training_iteration()
        else:
            # Commencer une nouvelle partie
            self.environment.board = chess.Board()
            self.last_move_time = (
                pygame.time.get_ticks() + 1000
            )  # Pause de 1s entre les parties

    def complete_training_iteration(self):
        """Compl√®te une it√©ration d'entra√Ænement."""
        print(f"\n‚úÖ It√©ration {self.training_iteration + 1} termin√©e!")
        print(f"üìä {self.training_games_played} parties jou√©es")

        # En mode interface, on ne fait pas l'entra√Ænement complet
        # (trop lourd), mais on simule la progression
        self.training_iteration += 1

        # Continuer automatiquement l'entra√Ænement si on est en mode training
        if self.training_mode:
            print(
                f"üîÑ D√©marrage automatique de l'it√©ration {self.training_iteration + 1}"
            )
            # Petite pause de 2 secondes puis red√©marrage automatique
            self.training_auto_play = False
            self.last_move_time = pygame.time.get_ticks() + 2000  # 2s de pause
            # On va red√©marrer dans handle_training
        else:
            self.training_auto_play = False
            print(f"üîÑ Pr√™t pour l'it√©ration {self.training_iteration + 1}")
            print("   ‚Ä¢ Appuyez sur S pour continuer l'entra√Ænement")

    def handle_automatic_training(self):
        """G√®re l'entra√Ænement automatique jusqu'√† convergence."""
        current_time = pygame.time.get_ticks()

        # Contr√¥ler la vitesse d'affichage
        if hasattr(self, "last_auto_training_update"):
            if current_time - self.last_auto_training_update < self.auto_training_speed:
                return

        self.last_auto_training_update = current_time

        # Si pas de partie en cours, en d√©marrer une nouvelle
        if (
            not hasattr(self, "auto_training_game_active")
            or not self.auto_training_game_active
        ):
            self.start_auto_training_game()
            return

        # Jouer le prochain coup
        board = self.environment.board

        if board.is_game_over():
            self.finish_auto_training_game()
            return

        # Obtenir le coup de l'IA
        try:
            move = self.get_ai_move(board, time_budget=1.0)
            if move and move in board.legal_moves:
                board.push(move)
                self.update_evaluation()

                # Afficher le coup
                move_str = f"{'Blanc' if not board.turn else 'Noir'}: {move}"
                print(f"üéØ Auto-training: {move_str}")

        except Exception as e:
            print(f"‚ö†Ô∏è Erreur pendant l'auto-training: {e}")
            self.auto_training_active = False

    def start_auto_training_game(self):
        """D√©marre une nouvelle partie d'entra√Ænement automatique."""
        self.environment.board = chess.Board()
        self.auto_training_game_active = True
        self.auto_training_game_count += 1

        print(
            f"\nüéÆ Partie {self.auto_training_game_count} - It√©ration {self.auto_training_iteration + 1}"
        )

    def finish_auto_training_game(self):
        """Termine une partie d'entra√Ænement automatique."""
        result = self.environment.board.result()
        self.auto_training_game_active = False

        print(f"üèÅ Partie {self.auto_training_game_count} termin√©e: {result}")

        # V√©rifier si on a assez de parties pour cette it√©ration
        games_per_iteration = 1  # üöÄ RAPIDE : Entra√Ænement apr√®s chaque partie !

        if self.auto_training_game_count >= games_per_iteration:
            self.complete_auto_training_iteration()
        else:
            # Pause tr√®s courte entre les parties pour acc√©l√©rer
            self.last_auto_training_update = (
                pygame.time.get_ticks() + 200
            )  # 200ms au lieu de 1000ms

    def complete_auto_training_iteration(self):
        """Compl√®te une it√©ration d'entra√Ænement automatique."""
        self.auto_training_iteration += 1
        self.auto_training_game_count = 0

        print(f"\n‚úÖ It√©ration {self.auto_training_iteration} termin√©e!")

        # Effectuer l'entra√Ænement r√©el avec le trainer appropri√©
        current_trainer = (
            self.hybrid_trainer if self.use_hybrid_trainer else self.trainer
        )

        if current_trainer:
            try:
                print(
                    f"üß† Entra√Ænement du r√©seau avec trainer {'hybride' if self.use_hybrid_trainer else 'standard'}..."
                )

                # üéØ VRAIE COLLECTE : Jouer une partie avec le trainer pour obtenir les donn√©es
                print("üìä G√©n√©ration d'une partie d'entra√Ænement...")
                game_data = current_trainer.play_game_hybrid(verbose=False)
                games_data = [game_data]  # Liste avec une partie

                if hasattr(current_trainer, "train_network"):
                    # Entra√Æner avec les vraies donn√©es de partie
                    current_trainer.train_network(games_data)
                    print("üìà R√©seau entra√Æn√© avec succ√®s!")
                else:
                    print("‚ö†Ô∏è Pas de m√©thode d'entra√Ænement disponible")

            except Exception as e:
                print(f"‚ö†Ô∏è Erreur pendant l'entra√Ænement: {e}")

        # V√©rifier si on continue
        if self.auto_training_iteration >= self.auto_training_max_iterations:
            print("üéâ ENTRA√éNEMENT AUTOMATIQUE TERMIN√â!")
            print("üèÜ Nombre maximum d'it√©rations atteint")
            self.auto_training_active = False
            self.training_mode = False
        else:
            progress = (
                self.auto_training_iteration / self.auto_training_max_iterations
            ) * 100
            print(
                f"üîÑ D√©marrage it√©ration {self.auto_training_iteration + 1} (Progr√®s: {progress:.1f}%)"
            )
            # Petite pause entre les it√©rations
            self.last_auto_training_update = (
                pygame.time.get_ticks() + 1000
            )  # 1s au lieu de 2s

    def get_3d_offset(self, file: int, rank: int) -> Tuple[int, int]:
        """Calcule l'offset 3D pour une case donn√©e."""
        # Facteur de profondeur simple
        depth_factor = 0.3

        # Calcul de l'offset bas√© sur la rotation
        x_offset = int(
            (rank - 3.5)
            * math.sin(math.radians(self.camera.rotation_y))
            * depth_factor
            * 10
        )
        y_offset = int(
            (rank - 3.5)
            * math.sin(math.radians(self.camera.rotation_x))
            * depth_factor
            * 10
        )

        return x_offset, y_offset

    def screen_to_board(self, screen_pos: Tuple[int, int]) -> Optional[int]:
        """Convertit une position √©cran en case d'√©chiquier."""
        x, y = screen_pos

        # Centrer sur l'√©chiquier
        board_start_x = (self.WINDOW_WIDTH - self.BOARD_SIZE) // 2
        board_start_y = (self.WINDOW_HEIGHT - self.BOARD_SIZE) // 2

        # V√©rifier si dans les limites du plateau
        if (
            x < board_start_x
            or x >= board_start_x + self.BOARD_SIZE
            or y < board_start_y
            or y >= board_start_y + self.BOARD_SIZE
        ):
            return None

        # Convertir en coordonn√©es de case
        file = (x - board_start_x) // self.CELL_SIZE
        rank = 7 - ((y - board_start_y) // self.CELL_SIZE)

        # V√©rifier les limites
        if 0 <= file <= 7 and 0 <= rank <= 7:
            return chess.square(file, rank)
        return None

    def draw_board(self):
        """Dessine l'√©chiquier avec effet 3D."""
        board_start_x = (self.WINDOW_WIDTH - self.BOARD_SIZE) // 2
        board_start_y = (self.WINDOW_HEIGHT - self.BOARD_SIZE) // 2

        for rank in range(8):
            for file in range(8):
                # Couleur de la case
                is_light = (rank + file) % 2 == 0
                color = (
                    self.COLORS["light_square"]
                    if is_light
                    else self.COLORS["dark_square"]
                )

                # Position de base
                x = board_start_x + file * self.CELL_SIZE
                y = board_start_y + (7 - rank) * self.CELL_SIZE

                # Effet 3D
                x_offset, y_offset = self.get_3d_offset(file, rank)

                # Dessiner la case avec l'offset 3D
                rect = pygame.Rect(
                    x + x_offset, y + y_offset, self.CELL_SIZE, self.CELL_SIZE
                )
                pygame.draw.rect(self.screen, color, rect)
                pygame.draw.rect(self.screen, (0, 0, 0), rect, 1)

                # Ombre pour l'effet de profondeur
                if x_offset != 0 or y_offset != 0:
                    shadow_rect = pygame.Rect(
                        x + 2, y + 2, self.CELL_SIZE, self.CELL_SIZE
                    )
                    shadow_color = tuple(max(0, c - 50) for c in color)
                    pygame.draw.rect(self.screen, shadow_color, shadow_rect)

    def draw_piece(self, piece: chess.Piece, square: int):
        """Dessine une pi√®ce avec effet 3D."""
        file = chess.square_file(square)
        rank = chess.square_rank(square)

        board_start_x = (self.WINDOW_WIDTH - self.BOARD_SIZE) // 2
        board_start_y = (self.WINDOW_HEIGHT - self.BOARD_SIZE) // 2

        x = board_start_x + file * self.CELL_SIZE
        y = board_start_y + (7 - rank) * self.CELL_SIZE

        # Effet 3D
        x_offset, y_offset = self.get_3d_offset(file, rank)
        center_x = x + self.CELL_SIZE // 2 + x_offset
        center_y = y + self.CELL_SIZE // 2 + y_offset

        # Couleur de la pi√®ce
        color = (
            self.COLORS["white_piece"] if piece.color else self.COLORS["black_piece"]
        )

        # Symboles des pi√®ces
        symbols = {
            chess.PAWN: "‚ôü" if piece.color else "‚ôü",
            chess.ROOK: "‚ôú" if piece.color else "‚ôú",
            chess.KNIGHT: "‚ôû" if piece.color else "‚ôû",
            chess.BISHOP: "‚ôù" if piece.color else "‚ôù",
            chess.QUEEN: "‚ôõ" if piece.color else "‚ôõ",
            chess.KING: "‚ôö" if piece.color else "‚ôö",
        }

        # Utiliser des cercles color√©s avec des lettres
        piece_letters = {
            chess.PAWN: "P",
            chess.ROOK: "R",
            chess.KNIGHT: "N",
            chess.BISHOP: "B",
            chess.QUEEN: "Q",
            chess.KING: "K",
        }

        # Effet de hauteur pour le 3D
        height_offset = int(abs(x_offset + y_offset) * 0.5)

        # Ombre de la pi√®ce
        pygame.draw.circle(
            self.screen,
            (0, 0, 0, 100),
            (center_x + 3, center_y + 3 - height_offset),
            self.CELL_SIZE // 3,
        )

        # Corps de la pi√®ce
        pygame.draw.circle(
            self.screen,
            color,
            (center_x, center_y - height_offset),
            self.CELL_SIZE // 3,
        )

        # Bordure
        border_color = (0, 0, 0) if piece.color else (255, 255, 255)
        pygame.draw.circle(
            self.screen,
            border_color,
            (center_x, center_y - height_offset),
            self.CELL_SIZE // 3,
            2,
        )

        # Lettre de la pi√®ce
        letter = piece_letters[piece.piece_type]
        text_color = (0, 0, 0) if piece.color else (255, 255, 255)
        text_surface = self.font.render(letter, True, text_color)
        text_rect = text_surface.get_rect(center=(center_x, center_y - height_offset))
        self.screen.blit(text_surface, text_rect)

    def draw_highlights(self):
        """Dessine les surlignages pour la case s√©lectionn√©e et les mouvements possibles."""
        board_start_x = (self.WINDOW_WIDTH - self.BOARD_SIZE) // 2
        board_start_y = (self.WINDOW_HEIGHT - self.BOARD_SIZE) // 2

        # Surligner la case s√©lectionn√©e
        if self.selected_square is not None:
            file = chess.square_file(self.selected_square)
            rank = chess.square_rank(self.selected_square)
            x = board_start_x + file * self.CELL_SIZE
            y = board_start_y + (7 - rank) * self.CELL_SIZE

            x_offset, y_offset = self.get_3d_offset(file, rank)
            highlight_surface = pygame.Surface(
                (self.CELL_SIZE, self.CELL_SIZE), pygame.SRCALPHA
            )
            highlight_surface.fill(self.COLORS["selected"])
            self.screen.blit(highlight_surface, (x + x_offset, y + y_offset))

        # Surligner les mouvements possibles
        for move_square in self.possible_moves:
            file = chess.square_file(move_square)
            rank = chess.square_rank(move_square)
            x = board_start_x + file * self.CELL_SIZE
            y = board_start_y + (7 - rank) * self.CELL_SIZE

            x_offset, y_offset = self.get_3d_offset(file, rank)
            move_surface = pygame.Surface(
                (self.CELL_SIZE, self.CELL_SIZE), pygame.SRCALPHA
            )
            move_surface.fill(self.COLORS["possible_move"])
            self.screen.blit(move_surface, (x + x_offset, y + y_offset))

        # Afficher les suggestions IA
        if self.show_ai_hints and self.ai_analysis:
            for i, (move, prob) in enumerate(self.ai_analysis["top_moves"][:3]):
                file = chess.square_file(move.to_square)
                rank = chess.square_rank(move.to_square)
                x = board_start_x + file * self.CELL_SIZE
                y = board_start_y + (7 - rank) * self.CELL_SIZE

                x_offset, y_offset = self.get_3d_offset(file, rank)
                ai_surface = pygame.Surface(
                    (self.CELL_SIZE, self.CELL_SIZE), pygame.SRCALPHA
                )
                # Intensit√© bas√©e sur la probabilit√©
                alpha = int(50 + prob * 100)
                color = (*self.COLORS["ai_suggestion"][:3], alpha)
                ai_surface.fill(color)
                self.screen.blit(ai_surface, (x + x_offset, y + y_offset))

    def draw_coordinates(self):
        """Dessine les coordonn√©es A-H et 1-8 autour du plateau."""
        board_start_x = (self.WINDOW_WIDTH - self.BOARD_SIZE) // 2
        board_start_y = (self.WINDOW_HEIGHT - self.BOARD_SIZE) // 2

        # Font plus lisible pour les coordonn√©es
        coord_font = pygame.font.Font(None, 28)

        # Couleur des coordonn√©es - blanc avec bordure noire pour la visibilit√©
        coord_color = (255, 255, 255)
        border_color = (0, 0, 0)

        # Dessiner les lettres A-H (colonnes)
        for file in range(8):
            letter = chr(ord("A") + file)
            x = board_start_x + file * self.CELL_SIZE + self.CELL_SIZE // 2

            # En haut du plateau
            y_top = board_start_y - 25
            # Bordure noire
            for dx in [-1, 0, 1]:
                for dy in [-1, 0, 1]:
                    if dx != 0 or dy != 0:
                        border_surface = coord_font.render(letter, True, border_color)
                        border_rect = border_surface.get_rect(
                            center=(x + dx, y_top + dy)
                        )
                        self.screen.blit(border_surface, border_rect)
            # Texte blanc
            text_surface = coord_font.render(letter, True, coord_color)
            text_rect = text_surface.get_rect(center=(x, y_top))
            self.screen.blit(text_surface, text_rect)

            # En bas du plateau
            y_bottom = board_start_y + self.BOARD_SIZE + 15
            # Bordure noire
            for dx in [-1, 0, 1]:
                for dy in [-1, 0, 1]:
                    if dx != 0 or dy != 0:
                        border_surface = coord_font.render(letter, True, border_color)
                        border_rect = border_surface.get_rect(
                            center=(x + dx, y_bottom + dy)
                        )
                        self.screen.blit(border_surface, border_rect)
            # Texte blanc
            text_surface = coord_font.render(letter, True, coord_color)
            text_rect = text_surface.get_rect(center=(x, y_bottom))
            self.screen.blit(text_surface, text_rect)

        # Dessiner les chiffres 1-8 (rang√©es)
        for rank in range(8):
            number = str(8 - rank)  # Inversion car rank 0 = 8√®me rang√©e
            y = board_start_y + rank * self.CELL_SIZE + self.CELL_SIZE // 2

            # √Ä gauche du plateau
            x_left = board_start_x - 25
            # Bordure noire
            for dx in [-1, 0, 1]:
                for dy in [-1, 0, 1]:
                    if dx != 0 or dy != 0:
                        border_surface = coord_font.render(number, True, border_color)
                        border_rect = border_surface.get_rect(
                            center=(x_left + dx, y + dy)
                        )
                        self.screen.blit(border_surface, border_rect)
            # Texte blanc
            text_surface = coord_font.render(number, True, coord_color)
            text_rect = text_surface.get_rect(center=(x_left, y))
            self.screen.blit(text_surface, text_rect)

            # √Ä droite du plateau
            x_right = board_start_x + self.BOARD_SIZE + 20
            # Bordure noire
            for dx in [-1, 0, 1]:
                for dy in [-1, 0, 1]:
                    if dx != 0 or dy != 0:
                        border_surface = coord_font.render(number, True, border_color)
                        border_rect = border_surface.get_rect(
                            center=(x_right + dx, y + dy)
                        )
                        self.screen.blit(border_surface, border_rect)
            # Texte blanc
            text_surface = coord_font.render(number, True, coord_color)
            text_rect = text_surface.get_rect(center=(x_right, y))
            self.screen.blit(text_surface, text_rect)

    def get_ai_move(
        self,
        board: chess.Board,
        time_budget: float = 15.0,  # üöÄ Plus de force par d√©faut
    ) -> Optional[chess.Move]:
        """
        Obtient un coup de l'IA (trainer hybride ou standard selon configuration).

        Args:
            board: Position actuelle
            time_budget: Budget de temps en secondes

        Returns:
            Meilleur coup selon l'IA, ou None si erreur
        """
        # Utiliser le trainer hybride si activ√©
        if self.use_hybrid_trainer and self.hybrid_trainer:
            try:
                # Utiliser MCTS correctement : run puis select_move
                move_distribution = self.hybrid_trainer.mcts.run(
                    board, num_simulations=200
                )
                move = self.hybrid_trainer.mcts.select_move(
                    move_distribution, temperature=0.1
                )
                if move:
                    print(f"üöÄ Trainer Hybride: {move}")
                return move
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur Trainer Hybride, fallback sur trainer standard: {e}")

        # Utiliser le trainer standard
        if self.trainer:
            try:
                # Utiliser MCTS correctement : run puis select_move
                move_distribution = self.trainer.mcts.run(board, num_simulations=200)
                move = self.trainer.mcts.select_move(move_distribution, temperature=0.1)
                if move:
                    print(f"ü§ñ Trainer Standard: {move}")
                return move
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur Trainer Standard: {e}")

        # Fallback sur l'ancien syst√®me d'IA si disponible
        if self.use_hybrid_ai and self.hybrid_ai_enabled:
            try:
                # Cr√©er le contexte de jeu
                context = GameContext(
                    time_left=time_budget,
                    move_number=len(board.move_stack) + 1,
                    is_critical=board.is_check() or len(list(board.legal_moves)) < 5,
                )

                # Obtenir la d√©cision de l'IA hybride
                decision = self.hybrid_ai.get_move(
                    board, context, mode=self.current_ai_mode
                )

                # Afficher les informations de la d√©cision
                print(
                    f"ÔøΩ IA Hybride Legacy: {decision.move} (eval: {decision.evaluation:.3f}, "
                    f"confiance: {decision.confidence:.3f}, m√©thode: {decision.method_used})"
                )

                return decision.move

            except Exception as e:
                print(f"‚ö†Ô∏è Erreur IA Hybride Legacy: {e}")

        # Dernier fallback sur l'IA standard
        if self.ai_enabled and self.ai_player:
            try:
                move = self.ai_player.get_move(board)
                if move:
                    print(f"üîÑ IA Standard Legacy: {move}")
                return move
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur IA Standard Legacy: {e}")

        return None

    def get_ai_analysis(self, board: chess.Board) -> Optional[dict]:
        """
        Obtient une analyse de position de l'IA.

        Args:
            board: Position √† analyser

        Returns:
            Dictionnaire d'analyse ou None
        """
        if self.use_hybrid_ai and self.hybrid_ai_enabled:
            try:
                # Analyse avec IA hybride
                context = GameContext(
                    time_left=15.0,  # üöÄ Plus de temps = Force sup√©rieure (depth 15)
                    move_number=len(board.move_stack) + 1,
                )

                decision = self.hybrid_ai.get_move(
                    board, context, mode=AIMode.HYBRID_DEEP
                )

                return {
                    "best_move": decision.move,
                    "evaluation": decision.evaluation,
                    "confidence": decision.confidence,
                    "method": decision.method_used,
                    "principal_variation": decision.principal_variation,
                    "alternatives": decision.alternative_moves,
                }

            except Exception as e:
                print(f"‚ö†Ô∏è Erreur analyse IA Hybride: {e}")

        # Fallback sur IA standard
        if self.ai_enabled and self.ai_player:
            try:
                return self.ai_player.get_move_analysis(board)
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur analyse IA Standard: {e}")

        return None

    def toggle_ai_mode(self):
        """Change le mode de l'IA hybride."""
        if not self.hybrid_ai_enabled:
            return

        modes = list(AIMode)
        current_index = modes.index(self.current_ai_mode)
        self.current_ai_mode = modes[(current_index + 1) % len(modes)]

        print(f"üîÑ Mode IA: {self.current_ai_mode.value}")

    def toggle_ai_continuous(self):
        """Active/d√©sactive l'IA continue."""
        self.ai_auto_play = not self.ai_auto_play
        if self.ai_auto_play:
            print("ü§ñ IA CONTINUE ACTIV√âE - L'IA jouera automatiquement ses coups")
            print("   ‚Ä¢ L'IA joue automatiquement apr√®s vos coups")
            print(
                "   ‚Ä¢ D√©lai configurable avec +/- (actuellement {}ms)".format(
                    self.ai_delay
                )
            )
            # Initialiser le syst√®me de collecte de partie si pas d√©j√† fait
            if not self.current_game_moves:
                self.start_new_game_collection()

            # Si on ne conna√Æt pas encore les couleurs, essayer de d√©tecter
            if self.ai_color is None:
                # Si c'est le d√©but de partie et que l'IA a d√©j√† jou√©, elle a les blancs
                if len(self.environment.board.move_stack) == 1:
                    self.ai_color = chess.WHITE
                    self.player_color = chess.BLACK
                    print("üéØ D√©tection: IA = Blancs, Joueur = Noirs")
                # Sinon, par d√©faut l'IA prend la couleur du tour actuel
                elif len(self.environment.board.move_stack) > 0:
                    self.ai_color = self.environment.board.turn
                    self.player_color = not self.environment.board.turn
                    ai_name = "Blancs" if self.ai_color else "Noirs"
                    player_name = "Blancs" if self.player_color else "Noirs"
                    print(f"üéØ D√©tection: IA = {ai_name}, Joueur = {player_name}")

            # Si c'est d√©j√† le tour de l'IA, la d√©clencher
            if (
                self.ai_color is not None
                and self.environment.board.turn == self.ai_color
                and not self.environment.board.is_game_over()
                and not self.waiting_for_ai
            ):
                self.waiting_for_ai = True
                self.ai_move_time = pygame.time.get_ticks() + self.ai_delay
                print(f"‚è≥ L'IA va jouer dans {self.ai_delay}ms...")
        else:
            print("üéÆ IA MANUELLE - Appuyez sur 'I' pour chaque coup IA")
            self.waiting_for_ai = False

    def toggle_learning_mode(self):
        """Active/d√©sactive l'apprentissage pendant le jeu."""
        self.learning_from_games = not self.learning_from_games
        if self.learning_from_games:
            print("üß† APPRENTISSAGE ACTIV√â - L'IA apprend de vos parties")
            print("   ‚Ä¢ Les parties sont collect√©es pour l'entra√Ænement")
            print("   ‚Ä¢ L'IA s'am√©liore au fil des parties")
            if not self.current_game_moves:
                self.start_new_game_collection()
        else:
            print("üéØ MODE NORMAL - Pas d'apprentissage")

    def start_new_game_collection(self):
        """D√©marre la collecte d'une nouvelle partie."""
        self.current_game_moves = []
        self.game_start_time = pygame.time.get_ticks()

        # Message adapt√© selon l'entra√Æneur disponible
        trainer_type = (
            "HYBRIDE avec adaptation automatique"
            if self.hybrid_trainer
            else "CLASSIQUE"
        )
        print(f"üìù Nouvelle partie - L'IA apprendra avec l'entra√Æneur {trainer_type}")
        if self.hybrid_trainer:
            print(f"   üîÑ Adaptation automatique active")
            print(f"   üéØ √âvaluations Stockfish pr√©cises")

    def add_move_to_collection(self, move, board_before_move):
        """Ajoute un mouvement √† la collection de la partie actuelle."""
        if self.learning_from_games:
            move_data = {
                "move": move,
                "board_fen": board_before_move.fen(),
                "timestamp": pygame.time.get_ticks() - self.game_start_time,
                "player": "human" if board_before_move.turn else "ai",
            }
            self.current_game_moves.append(move_data)

    def finish_game_collection(self, result):
        """Termine la collecte de la partie et la sauvegarde pour l'entra√Ænement."""
        if self.learning_from_games and self.current_game_moves:
            game_data = {
                "moves": self.current_game_moves,
                "result": result,
                "duration": pygame.time.get_ticks() - self.game_start_time,
                "timestamp": pygame.time.get_ticks(),
            }
            self.collected_games.append(game_data)

            print(
                f"üìö Partie sauvegard√©e ({len(self.current_game_moves)} coups, r√©sultat: {result})"
            )
            print(f"   Total parties collect√©es: {len(self.collected_games)}")

            # üöÄ NOUVEAU : Entra√Æner apr√®s CHAQUE partie (pas seulement apr√®s 5)
            if (
                self.trainer and len(self.current_game_moves) > 5
            ):  # Parties assez longues
                print("üéì Entra√Ænement imm√©diat sur la partie termin√©e...")
                self.run_micro_training()

            # Red√©marrer la collecte pour la prochaine partie
            self.start_new_game_collection()

    def run_micro_training(self):
        """Lance un micro-entra√Ænement avec les parties collect√©es."""
        # üöÄ UTILISER L'ENTRA√éNEUR HYBRIDE PAR D√âFAUT si disponible
        current_trainer = self.hybrid_trainer if self.hybrid_trainer else self.trainer

        if not current_trainer or len(self.collected_games) < 2:
            return

        try:
            trainer_type = (
                "HYBRIDE avec adaptation automatique"
                if self.hybrid_trainer
                else "CLASSIQUE"
            )
            print(
                f"üèãÔ∏è MICRO-ENTRA√éNEMENT {trainer_type} - Apprentissage des derni√®res parties..."
            )

            # üöÄ VRAI ENTRA√éNEMENT avec les parties collect√©es !
            from ..ai.training import GameData
            from ..ai.hybrid_training import HybridGameData
            from ..ai.network import encode_board

            games_trained = 0
            total_loss = 0.0

            for game_data in self.collected_games[
                -3:
            ]:  # Prendre les 3 derni√®res parties
                try:
                    # Reconstruire la partie depuis les coups stock√©s
                    board = chess.Board()
                    positions = []
                    board_positions = []
                    moves = []

                    for move_info in game_data["moves"]:
                        if "move" in move_info:
                            move = move_info["move"]
                            positions.append(encode_board(board))
                            board_positions.append(board.copy())
                            moves.append(move.uci())
                            board.push(move)

                    if len(positions) > 5:  # Seulement si la partie est assez longue
                        result = game_data["result"]

                        # üöÄ UTILISER L'ENTRA√éNEUR HYBRIDE EN PRIORIT√â
                        if self.hybrid_trainer and hasattr(
                            self.hybrid_trainer, "train_single_game_hybrid"
                        ):
                            # Calculer valeurs Stockfish
                            values = self.hybrid_trainer._calculate_stockfish_values(
                                board_positions, result
                            )

                            # Politiques simplifi√©es
                            policies = []
                            stockfish_policies = []

                            for board_pos in board_positions:
                                legal_moves = list(board_pos.legal_moves)
                                if legal_moves:
                                    uniform_prob = 1.0 / len(legal_moves)
                                    dummy_policy = {
                                        move: uniform_prob for move in legal_moves
                                    }
                                    policies.append(dummy_policy)

                                    # Politique Stockfish
                                    try:
                                        best_move = self.hybrid_trainer.reference_evaluator.get_best_move(
                                            board_pos
                                        )
                                        if best_move and best_move in legal_moves:
                                            sf_policy = {}
                                            for move in legal_moves:
                                                if move == best_move:
                                                    sf_policy[move] = 0.8
                                                else:
                                                    sf_policy[move] = 0.2 / (
                                                        len(legal_moves) - 1
                                                    )
                                            stockfish_policies.append(sf_policy)
                                        else:
                                            stockfish_policies.append(dummy_policy)
                                    except:
                                        stockfish_policies.append(dummy_policy)
                                else:
                                    policies.append({})
                                    stockfish_policies.append({})

                            hybrid_game_data = HybridGameData(
                                positions=positions,
                                policies=policies,
                                values=values,
                                result=result,
                                moves=moves,
                                game_length=len(moves),
                                stockfish_policies=stockfish_policies,
                            )

                            metrics = self.hybrid_trainer.train_single_game_hybrid(
                                hybrid_game_data, verbose=False
                            )
                            print(
                                f"  ‚úÖ Partie {games_trained + 1} entrain√©e HYBRIDE (Loss: {metrics.get('total_loss', 0):.4f})"
                            )

                        elif current_trainer and hasattr(
                            current_trainer, "train_single_game"
                        ):
                            # Entra√Ænement classique en fallback
                            values = current_trainer._calculate_stockfish_values(
                                board_positions, result
                            )

                            policies = []
                            for board_pos in board_positions:
                                legal_moves = list(board_pos.legal_moves)
                                if legal_moves:
                                    uniform_prob = 1.0 / len(legal_moves)
                                    dummy_policy = {
                                        move: uniform_prob for move in legal_moves
                                    }
                                    policies.append(dummy_policy)
                                else:
                                    policies.append({})

                            classic_game_data = GameData(
                                positions=positions,
                                policies=policies,
                                values=values,
                                result=result,
                                moves=moves,
                                game_length=len(moves),
                            )

                            metrics = current_trainer.train_single_game(
                                classic_game_data, verbose=False
                            )
                            print(
                                f"  ‚úÖ Partie {games_trained + 1} entrain√©e CLASSIQUE (Loss: {metrics.get('total_loss', 0):.4f})"
                            )

                        total_loss += metrics.get("total_loss", 0)
                        games_trained += 1

                except Exception as e:
                    print(f"  ‚ö†Ô∏è Erreur partie {game_data.get('result', '?')}: {e}")
                    continue

            if games_trained > 0:
                avg_loss = total_loss / games_trained
                print(
                    f"‚ú® Micro-entra√Ænement termin√©! {games_trained} parties entrain√©es"
                )
                print(f"   Loss moyenne: {avg_loss:.4f}")
                if self.hybrid_trainer:
                    print(f"   üîÑ Adaptation automatique appliqu√©e")
                print(f"   L'IA s'am√©liore en continu ! üöÄ")
            else:
                print("‚ö†Ô∏è Aucune partie n'a pu √™tre entrain√©e")

            # Garder seulement les 10 derni√®res parties pour √©viter l'accumulation
            if len(self.collected_games) > 10:
                self.collected_games = self.collected_games[-10:]

        except Exception as e:
            print(f"‚ö†Ô∏è Erreur pendant le micro-entra√Ænement: {e}")
            import traceback

            traceback.print_exc()

    def handle_ai_continuous_play(self):
        """G√®re l'IA continue contre le joueur."""
        current_time = pygame.time.get_ticks()
        board = self.environment.board

        # Si les couleurs ne sont pas encore d√©tect√©es, ne pas agir
        if self.ai_color is None:
            return

        # V√©rifier si c'est au tour de l'IA et qu'on attend son coup
        if (
            board.turn == self.ai_color  # Tour de l'IA
            and not self.waiting_for_ai
            and not board.is_game_over()
            and not self.training_mode
        ):  # Pas en mode entra√Ænement

            # D√©marrer l'attente du coup IA
            self.waiting_for_ai = True
            self.ai_move_time = current_time + self.ai_delay
            ai_color_name = "Blancs" if self.ai_color else "Noirs"
            print(f"‚è≥ L'IA ({ai_color_name}) r√©fl√©chit... (d√©lai: {self.ai_delay}ms)")

        # Ex√©cuter le coup IA si le d√©lai est √©coul√©
        elif (
            self.waiting_for_ai
            and current_time >= self.ai_move_time
            and not board.is_game_over()
        ):

            self.execute_ai_move()
            self.waiting_for_ai = False

    def execute_ai_move(self):
        """Ex√©cute un coup de l'IA."""
        board = self.environment.board

        try:
            # Sauvegarder l'√©tat avant le coup pour la collecte
            board_before = board.copy()

            # Obtenir le coup de l'IA
            move = self.get_ai_move(board, time_budget=2.0)

            if move and move in board.legal_moves:
                # Ajouter le coup √† la collection
                self.add_move_to_collection(move, board_before)

                # Jouer le coup
                board.push(move)

                print(f"ü§ñ IA: {move}")

                # Reset des s√©lections
                self.selected_square = None
                self.possible_moves = []

                # Mettre √† jour l'√©valuation
                self.update_evaluation()

                # V√©rifier si la partie est termin√©e
                if board.is_game_over():
                    result = board.result()
                    print(f"üèÅ Partie termin√©e: {result}")
                    self.finish_game_collection(result)

            else:
                print("‚ùå L'IA n'a pas pu trouver de coup valide")

        except Exception as e:
            print(f"‚ùå Erreur lors du coup IA: {e}")
            self.waiting_for_ai = False

    def update_evaluation(self):
        """Met √† jour les √©valuations de la position actuelle."""
        # 1. √âvaluation de r√©f√©rence (Stockfish)
        if self.reference_evaluator:
            try:
                self.reference_evaluation = self.reference_evaluator.evaluate_position(
                    self.environment.board
                )
                self.reference_history.append(self.reference_evaluation)
                if len(self.reference_history) > 100:
                    self.reference_history = self.reference_history[-100:]
            except Exception as e:
                print(f"‚ö†Ô∏è  Erreur √©valuation r√©f√©rence : {e}")

        # 2. √âvaluation de l'IA (si disponible)
        if self.ai_player:
            try:
                if hasattr(self.ai_player, "evaluate_position"):
                    value, _ = self.ai_player.evaluate_position(self.environment.board)
                    self.current_evaluation = max(-1.0, min(1.0, value))
                elif hasattr(self.ai_player, "get_move_analysis"):
                    analysis = self.ai_player.get_move_analysis(self.environment.board)
                    self.current_evaluation = max(
                        -1.0, min(1.0, analysis.get("evaluation", 0.0))
                    )

                # Ajouter √† l'historique
                self.evaluation_history.append(self.current_evaluation)
                if len(self.evaluation_history) > 100:
                    self.evaluation_history = self.evaluation_history[-100:]

            except Exception as e:
                # En cas d'erreur, garder la derni√®re √©valuation
                pass

    def draw_evaluation_bar(self):
        """Dessine les barres d'√©valuation sur le c√¥t√© droit."""
        if not self.show_evaluation_bar:
            return

        # Position des barres (c√¥t√© droit)
        board_start_x = (self.WINDOW_WIDTH - self.BOARD_SIZE) // 2
        bars_start_x = board_start_x + self.BOARD_SIZE + 60
        bar_y = (self.WINDOW_HEIGHT - self.eval_bar_height) // 2

        # Dessiner barre de r√©f√©rence (gauche)
        self._draw_single_evaluation_bar(
            bars_start_x,
            bar_y,
            self.reference_evaluation,
            self.reference_history,
            "R√©f√©rence",
            "Stockfish" if self.reference_evaluator else "Basique",
            "ref",
        )

        # Dessiner barre IA (droite)
        ai_bar_x = bars_start_x + self.eval_bar_width + 20
        self._draw_single_evaluation_bar(
            ai_bar_x,
            bar_y,
            self.current_evaluation,
            self.evaluation_history,
            "IA AlphaZero",
            "En apprentissage",
            "ai",
        )

        # L√©gende g√©n√©rale
        legend_x = bars_start_x + self.eval_bar_width
        legend_y = bar_y + self.eval_bar_height + 50

        # Afficher la diff√©rence
        diff = abs(self.reference_evaluation - self.current_evaluation)
        diff_text = f"√âcart: {diff:.2f}"
        diff_color = (
            (255, 100, 100)
            if diff > 0.5
            else (255, 255, 100) if diff > 0.2 else (100, 255, 100)
        )

        diff_surface = pygame.font.Font(None, 20).render(diff_text, True, diff_color)
        diff_rect = diff_surface.get_rect(center=(legend_x, legend_y))
        self.screen.blit(diff_surface, diff_rect)

    def _draw_single_evaluation_bar(
        self, x, y, evaluation, history, title, subtitle, color_prefix
    ):
        """Dessine une barre d'√©valuation individuelle."""
        # Couleurs selon le pr√©fixe
        border_color = self.COLORS[f"{color_prefix}_border"]
        black_color = self.COLORS[f"{color_prefix}_black"]
        white_color = self.COLORS[f"{color_prefix}_white"]

        # Fond de la barre
        bar_rect = pygame.Rect(x, y, self.eval_bar_width, self.eval_bar_height)
        pygame.draw.rect(self.screen, border_color, bar_rect, 2)

        # Calculer la hauteur des sections blanc/noir
        normalized_eval = (evaluation + 1.0) / 2.0  # 0 √† 1
        white_height = int(normalized_eval * self.eval_bar_height)
        black_height = self.eval_bar_height - white_height

        # Dessiner la section noire (en haut)
        if black_height > 0:
            black_rect = pygame.Rect(
                x + 2, y + 2, self.eval_bar_width - 4, black_height - 2
            )
            pygame.draw.rect(self.screen, black_color, black_rect)

        # Dessiner la section blanche (en bas)
        if white_height > 0:
            white_rect = pygame.Rect(
                x + 2, y + black_height, self.eval_bar_width - 4, white_height - 2
            )
            pygame.draw.rect(self.screen, white_color, white_rect)

        # Ligne de milieu (√©galit√©)
        middle_y = y + self.eval_bar_height // 2
        pygame.draw.line(
            self.screen,
            (255, 255, 0),
            (x, middle_y),
            (x + self.eval_bar_width, middle_y),
            2,
        )

        # Titre
        title_surface = pygame.font.Font(None, 20).render(
            title, True, self.COLORS["eval_text"]
        )
        title_rect = title_surface.get_rect(
            center=(x + self.eval_bar_width // 2, y - 40)
        )
        self.screen.blit(title_surface, title_rect)

        # Sous-titre
        subtitle_surface = pygame.font.Font(None, 16).render(
            subtitle, True, (200, 200, 200)
        )
        subtitle_rect = subtitle_surface.get_rect(
            center=(x + self.eval_bar_width // 2, y - 25)
        )
        self.screen.blit(subtitle_surface, subtitle_rect)

        # Valeur num√©rique
        eval_text = f"{evaluation:+.2f}"
        eval_surface = pygame.font.Font(None, 18).render(
            eval_text, True, self.COLORS["eval_text"]
        )
        eval_rect = eval_surface.get_rect(center=(x + self.eval_bar_width // 2, y - 8))
        self.screen.blit(eval_surface, eval_rect)

        # Mini-graphique historique (en dessous)
        if len(history) > 1:
            history_y = y + self.eval_bar_height + 10
            history_height = 30

            # Fond du mini-graphique
            history_rect = pygame.Rect(
                x, history_y, self.eval_bar_width, history_height
            )
            pygame.draw.rect(self.screen, (40, 40, 40), history_rect)
            pygame.draw.rect(self.screen, border_color, history_rect, 1)

            # Ligne de milieu
            middle_y = history_y + history_height // 2
            pygame.draw.line(
                self.screen,
                (100, 100, 100),
                (x, middle_y),
                (x + self.eval_bar_width, middle_y),
                1,
            )

            # Dessiner la courbe
            points = []
            recent_history = history[-20:]  # 20 derniers points
            for i, eval_val in enumerate(recent_history):
                point_x = x + (i * self.eval_bar_width) // len(recent_history)
                normalized = (eval_val + 1.0) / 2.0  # 0 √† 1
                point_y = history_y + history_height - int(normalized * history_height)
                points.append((point_x, point_y))

            if len(points) > 1:
                color = (100, 255, 150) if color_prefix == "ref" else (255, 200, 100)
                pygame.draw.lines(self.screen, color, False, points, 2)

    def draw_ui(self):
        """Dessine l'interface utilisateur."""
        # Informations sur le jeu
        turn_text = "Tour: " + ("Blancs" if self.environment.board.turn else "Noirs")
        text_surface = self.font.render(turn_text, True, (255, 255, 255))
        self.screen.blit(text_surface, (10, 10))

        # Mode d'entra√Ænement et IA continue
        if self.training_mode:
            if self.auto_training_active:
                mode_text = "ENTRA√éNEMENT AUTOMATIQUE"
                mode_color = (255, 215, 0)  # Or
            else:
                mode_text = "MODE ENTRA√éNEMENT"
                mode_color = (255, 255, 0)  # Jaune

            mode_surface = self.font.render(mode_text, True, mode_color)
            self.screen.blit(mode_surface, (10, 40))

            # Informations d'entra√Ænement
            if self.auto_training_active:
                training_info = [
                    f"It√©ration: {self.auto_training_iteration + 1}/{self.auto_training_max_iterations}",
                    f"Partie: {self.auto_training_game_count}/5",
                    f"Status: {'En pause' if self.auto_training_paused else 'Actif'}",
                    f"Vitesse: {self.auto_training_speed}ms",
                ]

                for i, info in enumerate(training_info):
                    color = (
                        (255, 255, 255)
                        if not self.auto_training_paused
                        else (255, 255, 0)
                    )
                    info_surface = pygame.font.Font(None, 24).render(info, True, color)
                    self.screen.blit(info_surface, (10, 70 + i * 25))
            else:
                training_info = [
                    f"It√©ration: {self.training_iteration + 1}",
                    f"Parties: {self.training_games_played}/{self.trainer.config.games_per_iteration if self.trainer else 0}",
                    f"Status: {'Auto-jeu' if self.training_auto_play else 'En pause'}",
                ]

                for i, info in enumerate(training_info):
                    color = (0, 255, 0) if self.training_auto_play else (255, 255, 255)
                    info_surface = pygame.font.Font(None, 24).render(info, True, color)
                    self.screen.blit(info_surface, (10, 70 + i * 25))

        # Affichage des modes IA continue et apprentissage
        if self.ai_auto_play or self.learning_from_games:
            y_offset = 70 if not self.training_mode else 170

            if self.ai_auto_play:
                ai_text = "ü§ñ IA CONTINUE ACTIV√âE"
                ai_color = (0, 255, 0)  # Vert
                if self.waiting_for_ai:
                    ai_text += " (‚è≥ r√©flexion...)"
                    ai_color = (255, 255, 0)  # Jaune pendant la r√©flexion
                ai_surface = self.font.render(ai_text, True, ai_color)
                self.screen.blit(ai_surface, (10, y_offset))
                y_offset += 30

                # D√©lai configur√©
                delay_text = f"D√©lai IA: {self.ai_delay}ms (+/- pour ajuster)"
                delay_surface = pygame.font.Font(None, 20).render(
                    delay_text, True, (200, 200, 200)
                )
                self.screen.blit(delay_surface, (10, y_offset))
                y_offset += 25

            if self.learning_from_games:
                learn_text = (
                    f"üß† APPRENTISSAGE ACTIF ({len(self.collected_games)} parties)"
                )
                learn_color = (100, 255, 100)  # Vert clair
                learn_surface = self.font.render(learn_text, True, learn_color)
                self.screen.blit(learn_surface, (10, y_offset))
                y_offset += 30

                if self.current_game_moves:
                    moves_text = (
                        f"Partie actuelle: {len(self.current_game_moves)} coups"
                    )
                    moves_surface = pygame.font.Font(None, 20).render(
                        moves_text, True, (200, 200, 200)
                    )
                    self.screen.blit(moves_surface, (10, y_offset))

        # Contr√¥les
        controls = [
            "Contr√¥les:",
            "Clic gauche: S√©lectionner/Jouer",
            "Clic droit + glisser: Rotation cam√©ra",
            "Molette: Zoom",
            "R: R√©initialiser cam√©ra",
            "H: Toggle hints IA",
            "I: Jouer coup IA",
            "C: IA continue ON/OFF",
            "L: Apprentissage ON/OFF",
            "M: Changer mode IA",
            "E: Toggle barre d'√©valuation",
        ]

        # Ajouter contr√¥les d'entra√Ænement
        if TRAINING_AVAILABLE and self.trainer:
            controls.extend(
                [
                    "T: Mode entra√Ænement",
                    "Y: Entra√Ænement automatique",
                    "S: D√©marrer/Arr√™ter auto-jeu",
                    "Espace: Pause/Reprendre",
                    "+/-: Vitesse entra√Ænement",
                    "√âchap: Arr√™ter entra√Ænement auto",
                ]
            )

        start_y = 160 if self.training_mode else 50
        for i, control in enumerate(controls):
            color = (255, 255, 255) if i == 0 else (200, 200, 200)
            if control.startswith("H:") and self.show_ai_hints:
                color = (0, 255, 0)  # Vert si hints actifs
            elif control.startswith("T:") and self.training_mode:
                color = (255, 255, 0)  # Jaune si mode entra√Ænement actif
            text_surface = pygame.font.Font(None, 24).render(control, True, color)
            self.screen.blit(text_surface, (10, start_y + i * 25))

        # Affichage du mode IA hybride
        if self.hybrid_ai:
            mode_y = start_y + len(controls) * 25 + 10
            mode_text = f"Mode IA: {self.hybrid_ai.current_mode.value}"
            mode_color = (100, 255, 100)  # Vert clair
            mode_surface = self.font.render(mode_text, True, mode_color)
            self.screen.blit(mode_surface, (10, mode_y))

        # Afficher les suggestions IA si actives
        if self.show_ai_hints and self.ai_analysis:
            y_pos = (
                start_y + len(controls) * 25 + 50
            )  # +50 pour laisser place au mode IA
            title = self.font.render("Suggestions IA:", True, (255, 255, 255))
            self.screen.blit(title, (10, y_pos))

            for i, (move, prob) in enumerate(self.ai_analysis["top_moves"][:3]):
                move_text = f"{i+1}. {move} ({prob:.1%})"
                surface = pygame.font.Font(None, 24).render(
                    move_text, True, self.COLORS["ai_suggestion"][:3]
                )
                self.screen.blit(surface, (10, y_pos + 25 + i * 20))

        # √âtat du jeu
        if self.environment.board.is_checkmate():
            winner = "Noirs" if self.environment.board.turn else "Blancs"
            game_text = self.font.render(
                f"√âchec et mat! {winner} gagnent!", True, (255, 0, 0)
            )
            self.screen.blit(game_text, (10, self.WINDOW_HEIGHT - 30))
        elif self.environment.board.is_stalemate():
            game_text = self.font.render("Pat! Match nul.", True, (255, 255, 0))
            self.screen.blit(game_text, (10, self.WINDOW_HEIGHT - 30))
        elif self.environment.board.is_check():
            game_text = self.font.render("√âchec!", True, (255, 100, 100))
            self.screen.blit(game_text, (10, self.WINDOW_HEIGHT - 30))

    def handle_click(self, pos: Tuple[int, int]):
        """G√®re les clics de souris."""
        square = self.screen_to_board(pos)
        if square is None:
            return

        print(f"üéØ Clic sur {chess.square_name(square)}")

        # Si aucune case s√©lectionn√©e
        if self.selected_square is None:
            piece = self.environment.board.piece_at(square)
            if piece and piece.color == self.environment.board.turn:
                self.selected_square = square
                # Stocker les mouvements complets pour g√©rer le roque et les promotions
                self.legal_moves_from_selected = [
                    move
                    for move in self.environment.board.legal_moves
                    if move.from_square == square
                ]
                self.possible_moves = [
                    move.to_square for move in self.legal_moves_from_selected
                ]
                print(
                    f"‚úÖ Pi√®ce s√©lectionn√©e: {piece} ({len(self.possible_moves)} mouvements)"
                )
            else:
                print("‚ùå Pas de pi√®ce valide √† s√©lectionner")
        else:
            # Tentative de mouvement
            if square == self.selected_square:
                # D√©s√©lection
                self.selected_square = None
                self.possible_moves = []
                self.legal_moves_from_selected = []
                print("‚ùå D√©s√©lection")
            elif square in self.possible_moves:
                # Mouvement valide - trouver le mouvement complet
                target_move = None
                for move in self.legal_moves_from_selected:
                    if move.to_square == square:
                        target_move = move
                        break

                if target_move:
                    try:
                        # Sauvegarder l'√©tat avant le coup pour la collecte
                        board_before = self.environment.board.copy()

                        # D√©tecter le type de mouvement avant de l'effectuer
                        is_castling = self.environment.board.is_castling(target_move)
                        is_en_passant = self.environment.board.is_en_passant(
                            target_move
                        )

                        if self.environment.make_move(target_move):
                            # Ajouter le coup √† la collection si l'apprentissage est activ√©
                            self.add_move_to_collection(target_move, board_before)

                            move_desc = f"{chess.square_name(self.selected_square)} ‚Üí {chess.square_name(square)}"
                            # Ajouter info sur le type de mouvement
                            if target_move.promotion:
                                move_desc += f" (promotion: {chess.piece_name(target_move.promotion)})"
                            elif is_castling:
                                move_desc += " (roque)"
                            elif is_en_passant:
                                move_desc += " (en passant)"

                            print(f"‚úÖ Mouvement: {move_desc}")
                            self.selected_square = None
                            self.possible_moves = []

                            # Mettre √† jour l'√©valuation apr√®s le coup
                            self.update_evaluation()
                            self.legal_moves_from_selected = []

                            # V√©rifier si la partie est termin√©e
                            if self.environment.board.is_game_over():
                                result = self.environment.board.result()
                                print(f"üèÅ Partie termin√©e: {result}")
                                self.finish_game_collection(result)
                            else:
                                # D√©tecter automatiquement les couleurs des joueurs
                                if self.player_color is None:
                                    # Le joueur vient de jouer, donc c'est sa couleur
                                    self.player_color = (
                                        not self.environment.board.turn
                                    )  # Couleur oppos√©e au tour actuel
                                    self.ai_color = (
                                        self.environment.board.turn
                                    )  # Tour actuel = IA
                                    print(
                                        f"üéØ D√©tection: Joueur = {'Blancs' if self.player_color else 'Noirs'}, IA = {'Blancs' if self.ai_color else 'Noirs'}"
                                    )

                                # D√©clencher l'IA si mode continu activ√© et c'est son tour
                                if (
                                    self.ai_auto_play
                                    and self.environment.board.turn == self.ai_color
                                    and not self.training_mode
                                    and not self.waiting_for_ai
                                ):
                                    self.waiting_for_ai = True
                                    self.ai_move_time = (
                                        pygame.time.get_ticks() + self.ai_delay
                                    )
                                    print(f"‚è≥ L'IA va jouer dans {self.ai_delay}ms...")
                        else:
                            print("‚ùå Mouvement invalide")
                    except Exception as e:
                        print(f"‚ùå Erreur: {e}")
                else:
                    print("‚ùå Mouvement non trouv√©")
            else:
                # Nouvelle s√©lection
                piece = self.environment.board.piece_at(square)
                if piece and piece.color == self.environment.board.turn:
                    self.selected_square = square
                    self.legal_moves_from_selected = [
                        move
                        for move in self.environment.board.legal_moves
                        if move.from_square == square
                    ]
                    self.possible_moves = [
                        move.to_square for move in self.legal_moves_from_selected
                    ]
                    print(
                        f"‚úÖ Nouvelle s√©lection: {piece} ({len(self.possible_moves)} mouvements)"
                    )
                else:
                    print("‚ùå Mouvement impossible")

    def handle_camera_rotation(self, rel: Tuple[int, int]):
        """G√®re la rotation de la cam√©ra."""
        dx, dy = rel
        self.camera.rotation_y += dx * 0.5
        self.camera.rotation_x = max(-60, min(60, self.camera.rotation_x + dy * 0.5))

    def reset_camera(self):
        """Remet la cam√©ra √† sa position par d√©faut."""
        self.camera.rotation_x = -30.0
        self.camera.rotation_y = 0.0
        self.camera.zoom = 1.0
        print("üì∑ Cam√©ra r√©initialis√©e")

    def run(self):
        """Boucle principale du jeu."""
        running = True

        while running:
            for event in pygame.event.get():
                if event.type == pygame.QUIT:
                    running = False

                elif event.type == pygame.MOUSEBUTTONDOWN:
                    if event.button == 1:  # Clic gauche
                        self.handle_click(event.pos)
                    elif event.button == 3:  # Clic droit
                        self.dragging_camera = True
                        self.last_mouse_pos = event.pos

                elif event.type == pygame.MOUSEBUTTONUP:
                    if event.button == 3:  # Rel√¢chement clic droit
                        self.dragging_camera = False

                elif event.type == pygame.MOUSEMOTION:
                    if self.dragging_camera:
                        rel = (
                            event.pos[0] - self.last_mouse_pos[0],
                            event.pos[1] - self.last_mouse_pos[1],
                        )
                        self.handle_camera_rotation(rel)
                        self.last_mouse_pos = event.pos

                elif event.type == pygame.MOUSEWHEEL:
                    self.camera.zoom += event.y * 0.1
                    self.camera.zoom = max(0.5, min(2.0, self.camera.zoom))

                elif event.type == pygame.KEYDOWN:
                    if event.key == pygame.K_r:
                        self.reset_camera()
                    elif event.key == pygame.K_h:
                        # Toggle pour afficher/masquer les hints IA
                        self.show_ai_hints = not self.show_ai_hints
                        if self.show_ai_hints and not self.ai_analysis:
                            # Analyser la position
                            self.ai_analysis = self.get_ai_analysis(
                                self.environment.board
                            )
                    elif event.key == pygame.K_i:
                        # Jouer le meilleur coup IA
                        if not self.environment.board.is_game_over():
                            move = self.get_ai_move(
                                self.environment.board, time_budget=3.0
                            )
                            if move and move in self.environment.board.legal_moves:
                                self.environment.board.push(move)
                                self.selected_square = None
                                self.possible_moves = []
                                self.ai_analysis = None  # Reset analysis apr√®s un coup
                                self.update_evaluation()  # Mettre √† jour l'√©valuation
                    elif event.key == pygame.K_m:
                        # Changer le mode de l'IA hybride
                        self.toggle_ai_mode()
                    elif event.key == pygame.K_t:
                        # Toggle mode d'entra√Ænement
                        if TRAINING_AVAILABLE and self.trainer:
                            self.toggle_training_mode()
                    elif event.key == pygame.K_y:
                        # Lancer l'entra√Ænement automatique jusqu'√† convergence
                        if (
                            TRAINING_AVAILABLE
                            and self.trainer
                            and not self.auto_training_active
                        ):
                            self.start_automatic_training()
                        elif self.auto_training_active:
                            print("üõë Arr√™t de l'entra√Ænement automatique")
                            self.auto_training_active = False
                            self.training_mode = False
                    elif event.key == pygame.K_e:
                        # Toggle barre d'√©valuation
                        self.show_evaluation_bar = not self.show_evaluation_bar
                        status = "activ√©e" if self.show_evaluation_bar else "d√©sactiv√©e"
                        print(f"üìä Barre d'√©valuation {status}")
                    elif event.key == pygame.K_s:
                        # D√©marrer/Arr√™ter auto-jeu d'entra√Ænement
                        if self.training_mode:
                            if not self.training_auto_play:
                                self.start_training_iteration()
                            else:
                                self.training_auto_play = False
                                print("‚è∏Ô∏è  Auto-jeu en pause")
                    elif event.key == pygame.K_SPACE:
                        # Pause/Reprendre en mode entra√Ænement
                        if self.training_mode or self.auto_training_active:
                            if self.auto_training_active:
                                self.auto_training_paused = (
                                    not self.auto_training_paused
                                )
                                status = (
                                    "repris"
                                    if not self.auto_training_paused
                                    else "en pause"
                                )
                                print(f"‚èØÔ∏è  Entra√Ænement automatique {status}")
                            else:
                                self.training_auto_play = not self.training_auto_play
                                status = (
                                    "repris" if self.training_auto_play else "en pause"
                                )
                                print(f"‚èØÔ∏è  Auto-jeu {status}")
                    elif event.key == pygame.K_PLUS or event.key == pygame.K_EQUALS:
                        # Acc√©l√©rer l'entra√Ænement OU r√©duire le d√©lai IA
                        if self.auto_training_active:
                            self.auto_training_speed = max(
                                100, self.auto_training_speed - 100
                            )
                            print(
                                f"‚ö° Vitesse d'entra√Ænement: {self.auto_training_speed}ms"
                            )
                        elif self.ai_auto_play:
                            self.ai_delay = max(500, self.ai_delay - 200)
                            print(f"‚ö° D√©lai IA r√©duit: {self.ai_delay}ms")
                    elif event.key == pygame.K_MINUS:
                        # Ralentir l'entra√Ænement OU augmenter le d√©lai IA
                        if self.auto_training_active:
                            self.auto_training_speed = min(
                                2000, self.auto_training_speed + 100
                            )
                            print(
                                f"üêå Vitesse d'entra√Ænement: {self.auto_training_speed}ms"
                            )
                        elif self.ai_auto_play:
                            self.ai_delay = min(5000, self.ai_delay + 200)
                            print(f"üêå D√©lai IA augment√©: {self.ai_delay}ms")
                    elif event.key == pygame.K_ESCAPE:
                        # Arr√™ter l'entra√Ænement automatique
                        if self.auto_training_active:
                            print("üõë Arr√™t de l'entra√Ænement automatique demand√©")
                            print("üíæ Sauvegarde d'urgence du mod√®le...")

                            # üöÄ SAUVEGARDE D'URGENCE !
                            current_trainer = (
                                self.hybrid_trainer
                                if self.use_hybrid_trainer
                                else self.trainer
                            )
                            if current_trainer and hasattr(
                                current_trainer, "save_model"
                            ):
                                try:
                                    current_trainer.save_model(
                                        f"hybrid_model_emergency_iter_{self.auto_training_iteration}.pt"
                                    )
                                    print("‚úÖ Mod√®le sauvegard√© avec succ√®s!")
                                except Exception as e:
                                    print(f"‚ö†Ô∏è Erreur de sauvegarde: {e}")

                            self.auto_training_active = False
                            self.training_mode = False
                    elif event.key == pygame.K_c:
                        # Toggle IA continue
                        self.toggle_ai_continuous()
                    elif event.key == pygame.K_l:
                        # Toggle apprentissage pendant le jeu
                        self.toggle_learning_mode()

            # Gestion de l'auto-jeu d'entra√Ænement
            if self.training_mode and not self.auto_training_active:
                self.handle_training_auto_play()

            # Gestion de l'entra√Ænement automatique
            if self.auto_training_active and not self.auto_training_paused:
                self.handle_automatic_training()

            # Gestion de l'IA continue contre le joueur
            if self.ai_auto_play and not self.training_mode:
                self.handle_ai_continuous_play()

            # Dessiner
            self.screen.fill(self.COLORS["background"])
            self.draw_board()
            self.draw_coordinates()
            self.draw_highlights()

            # Dessiner les pi√®ces
            for square in chess.SQUARES:
                piece = self.environment.board.piece_at(square)
                if piece:
                    self.draw_piece(piece, square)

            self.draw_evaluation_bar()
            self.draw_ui()

            pygame.display.flip()
            self.clock.tick(60)

        pygame.quit()


def main():
    """Fonction principale."""
    try:
        gui = SimpleChessGUI3D()
        gui.run()
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return False
    return True


if __name__ == "__main__":
    if not main():
        sys.exit(1)
